ğŸ“ Step 7 â€“ Bias & Toxicity Detection

In this step, we introduced the Bias and Toxicity Detection audit.
This module expands the AuditorAgentâ€™s capabilities by scanning text for biased or toxic language.

ğŸš€ Features Implemented

Added bias_detector.py

Maintains a small lexicon of toxic/biased words.

Detects occurrences in audit text.

Returns structured findings in JSON format.

Includes a summary helper (summarize_bias) for concise logging.

ğŸ“‚ File Overview

bias_detector.py â†’ Implements bias/toxicity scan logic.

Integrated with auditor.py (will orchestrate checks in the next step).