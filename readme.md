ğŸ›¡ï¸ AI Auditor

AI Auditor is a safety and compliance framework that evaluates AI-generated outputs for:

PII leakage (emails, phone numbers, IDs, etc.)

Toxicity & bias

Hallucinations / unsupported claims

It uses a mix of rule-based regex, trained ML classifiers, and rewriting agents to decide whether an output should PASS, FLAG, or FAIL.

ğŸš€ Features

ğŸ” Multi-check system â€“ runs PII, bias, and hallucination audits

ğŸ¤– Automatic rewrite â€“ unsafe text is rewritten with Gemini

ğŸ“Š Dashboard â€“ Streamlit UI for interactive demos

ğŸ§ª Reproducible experiments â€“ config-driven pipelines with metrics & reports

ğŸ—ï¸ Project Structure
AI AUDITOR
â”‚
â”œâ”€â”€ agent/                   # Entry scripts to run the full auditor pipeline
â”‚   â”œâ”€â”€ auditor.yaml          # Config file for orchestrating audit checks
â”‚   â””â”€â”€ run.py                # Launches auditor agent end-to-end
â”‚
â”œâ”€â”€ app/                     # High-level orchestration layer
â”‚   â”œâ”€â”€ auditor.py            # Main auditing logic
â”‚   â””â”€â”€ auditor_agent.py      # Agent wrapper around auditor for reuse
â”‚
â”œâ”€â”€ audit_service/            # Core audit microservice (stub API)
â”‚   â”œâ”€â”€ __main__.py           # Run module as script
â”‚   â”œâ”€â”€ adapters/             # Adapters for external models (e.g., Gemini)
â”‚   â”œâ”€â”€ audit_checks/         # PII, toxicity, hallucination checks
â”‚   â”‚   â””â”€â”€ prompts.py        # Prompt templates for LLM-based checks
â”‚   â”œâ”€â”€ core.py               # Core orchestration logic
â”‚   â”œâ”€â”€ main.py               # FastAPI entrypoint (stubbed for now)
â”‚   â”œâ”€â”€ models/               # Stored ML models
â”‚   â”‚   â””â”€â”€ toxicity_and_biasness/
â”‚   â”‚       â”œâ”€â”€ logistic.pkl
â”‚   â”‚       â””â”€â”€ tfidf_vectorizer.pkl
â”‚   â”œâ”€â”€ models.py             # Pydantic schemas for requests/responses
â”‚   â”œâ”€â”€ routers/              # API route handlers (audit endpoints)
â”‚   â”œâ”€â”€ services/             # Service clients (PII, toxicity, rewrite)
â”‚   â””â”€â”€ storage/              # In-memory or file-based logging
â”‚
â”œâ”€â”€ dashboard/                # Streamlit dashboard
â”‚   â””â”€â”€ app.py                 # Visual UI for audits
â”‚
â”‚
â”œâ”€â”€ harmful-classifier/       # ML classifier development
â”‚   â”œâ”€â”€ data/                  # Datasets for training & testing
â”‚   â”‚   â””â”€â”€ processed/          # Cleaned versions of datasets
â”‚   â”œâ”€â”€ models/                # Saved models (e.g., PII logistic regression)
â”‚   â”œâ”€â”€ reports/               # Training reports, metrics, confusion matrices
â”‚   â”œâ”€â”€ src/                   # Source code for training pipelines
â”‚   â”‚   â”œâ”€â”€ config.yaml         # Config (thresholds, paths)
â”‚   â”‚   â”œâ”€â”€ features/           # Feature engineering (regex, TF-IDF, etc.)
â”‚   â”‚   â”œâ”€â”€ models/             # Model inference & analysis
â”‚   â”‚   â””â”€â”€ pipeline/           # Service wrapper (FastAPI stub)
â”‚   â””â”€â”€ tests/                 # Unit tests
â”‚
â”œâ”€â”€ integrations/             # (Optional) Integrations (Notion/Slack stubs)
â”‚
â”œâ”€â”€ pyproject.toml            # Project metadata + scripts
â”œâ”€â”€ readme.md                 # (You are here ğŸš€)
â”œâ”€â”€ reports/                  # Extra analysis outputs
â””â”€â”€ requirements.txt          # Python dependencies

âš¡ Quickstart
1. Setup
git clone https://github.com/your-repo/ai-auditor.git
cd ai-auditor
pip install -r requirements.txt

2. Run Auditor
python agent/run.py --config agent/auditor.yaml

3. Launch Dashboard
streamlit run dashboard/app.py

ğŸ“Š Example Output

Input:

Call me at 9876543210 tomorrow.


Audit Result:

{
  "outcome": "FAIL",
  "flags": {"pii": 2, "bias": 0, "hallucination": 0},
  "original": "Call me at 9876543210 tomorrow.",
  "cleaned": "Call me tomorrow at [redacted]."
}

ğŸ¯ Why It Matters

Ensures responsible AI usage in real-world systems

Prevents PII leaks and unsafe outputs

Provides transparent PASS/FLAG/FAIL audit trail

Easily extensible with new models & datasets

Demo-ready (dashboard)

Tackles AI safety, a top concern for enterprises

Research-backed with ML, not just LLM prompts

Balanced between practicality and innovation