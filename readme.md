ğŸ›¡ï¸ AI Auditor

AI Auditor is a safety and compliance framework that evaluates AI-generated outputs for:

PII leakage (emails, phone numbers, IDs, etc.)

Toxicity & bias

Hallucinations / unsupported claims

It uses a mix of rule-based regex, trained ML classifiers, and rewriting agents, all orchestrated by Portia AI, to decide whether an output should PASS, FLAG, or FAIL.

ğŸš€ Features

ğŸ” Multi-check system â€“ runs PII, bias, and hallucination audits
ğŸ¤– Automatic rewrite â€“ unsafe text is rewritten with Gemini
ğŸ› ï¸ Portia Orchestration â€“ Portia acts as the hub, routing input/output through detectors and rewriters in real-time
ğŸ“Š Dashboard â€“ Streamlit UI for interactive demos
ğŸ§ª Reproducible experiments â€“ config-driven pipelines with metrics & reports

ğŸ•¸ï¸ How Portia Connects Everything

Portia AI is the central orchestrator of the pipeline:

User Input
   â”‚
   â–¼
[Portia] â†’ Input Audit  
   â”œâ”€â”€ PII Detector (regex/rules)  
   â”œâ”€â”€ Toxicity & Bias Classifier (ML)  
   â””â”€â”€ Policy Guard (prompt injection / unsafe intent)  

   â”‚
   â–¼
[LLM: GPT/Gemini/Other] â†’ generates raw output  
   â”‚
   â–¼
[Portia] â†’ Output Audit  
   â”œâ”€â”€ PII Sanitizer â†’ replaces with [EMAIL], [PHONE], etc.  
   â”œâ”€â”€ Toxicity Rewriter â†’ neutral rephrasing  
   â”œâ”€â”€ Hallucination Checker â†’ Wikipedia + Gemini fallback  
   â””â”€â”€ Gemini Adapter â†’ final rewrite pass  

   â”‚
   â–¼
Safe Output (PASS/FLAG/FAIL + cleaned text)


Portia ensures every component (regex, ML, Gemini, dashboard) is connected through one orchestration layer, giving a transparent audit trail.

ğŸ—ï¸ Project Structure
AI AUDITOR

â”‚

â”œâ”€â”€ agent/              # Entry scripts (Portia-driven pipelines)

â”‚   â”œâ”€â”€ auditor.yaml    # Config file (Portia orchestrator)

â”‚   â””â”€â”€ run.py          # Launches end-to-end auditor via Portia


â”‚

â”œâ”€â”€ app/                # High-level orchestration layer

â”‚   â”œâ”€â”€ auditor.py      # Main auditing logic (Portia orchestrated)

â”‚   â””â”€â”€ auditor_agent.py# Agent wrapper (Portia-powered)

â”‚

â”œâ”€â”€ audit_service/      # Core audit microservice

â”‚   â”œâ”€â”€ adapters/       # Gemini + Portia adapters

â”‚   â”œâ”€â”€ audit_checks/   # PII, toxicity, hallucination checks

â”‚   â”œâ”€â”€ core.py         # Orchestration glue with Portia

â”‚   â”œâ”€â”€ models/         # ML classifiers (toxicity, bias)

â”‚   â”œâ”€â”€ routers/        # API endpoints for audits

â”‚   â””â”€â”€ services/       # Portia service clients

â”‚

â”œâ”€â”€ dashboard/          # Streamlit dashboard (queries via Portia)

â”‚

â”œâ”€â”€ harmful-classifier/ # ML model training

â”‚

â””â”€â”€ ...


âš¡ Quickstart
git clone https://github.com/your-repo/ai-auditor.git
cd ai-auditor
pip install -r requirements.txt


Run full auditor (via Portia):

python agent/run.py --config agent/auditor.yaml


Launch dashboard:

streamlit run dashboard/app.py

ğŸ“Š Example Output

Input:

Call me at 9876543210 tomorrow.


Audit Result:

{
  "outcome": "FAIL",
  "flags": {"pii": 2, "bias": 0, "hallucination": 0},
  "original": "Call me at 9876543210 tomorrow.",
  "cleaned": "Call me tomorrow at [PHONE].",
  "orchestrator": "Portia AI"
}

ğŸ¯ Why It Matters

Ensures responsible AI usage in real-world systems

Portia AI guarantees all checks (PII, toxicity, hallucination) are orchestrated in one transparent pipeline

Prevents leaks, unsafe outputs, and bias at scale

Provides PASS/FLAG/FAIL audit trail with Portia-managed logs

Extensible with new checks, models, and adapters

Demo-ready dashboard
